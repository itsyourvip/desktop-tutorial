{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNf5oZRFDoc/vHxPs9b1LvU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsyourvip/desktop-tutorial/blob/main/TWSVM_ACC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from cvxopt import solvers, matrix\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n"
      ],
      "metadata": {
        "id": "rxlz5Sks2VBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin # import the BaseEstimator and ClassifierMixin\n",
        "\n",
        "class TWSVM(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, c1=1.0, c2=1.0, reg_term=1e-5):\n",
        "        self.c1 = c1\n",
        "        self.c2 = c2\n",
        "        self.reg_term = reg_term\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Matrix A (class 1 samples) and Matrix B (class -1 samples)\n",
        "        A = X[y == 1]\n",
        "        B = X[y == -1]\n",
        "\n",
        "        # Vectors of ones\n",
        "        e1 = np.ones((A.shape[0], 1))\n",
        "        e2 = np.ones((B.shape[0], 1))\n",
        "\n",
        "        # Define H = [A e1], G = [B e2]\n",
        "        H = np.column_stack((A, e1))\n",
        "        G = np.column_stack((B, e2))\n",
        "\n",
        "        # Helper function to check matrix conditioning\n",
        "        def is_well_conditioned(matrix):                            #doubt\n",
        "            condition_number = np.linalg.cond(matrix)\n",
        "            return condition_number < 1e10\n",
        "\n",
        "        # Solve QP for the first hyperplane\n",
        "        def solve_qp(H, G, e, c, reg_term):\n",
        "            HtH = np.dot(H.T, H) + reg_term * np.identity(H.shape[1])\n",
        "            if not is_well_conditioned(HtH):\n",
        "                return None\n",
        "\n",
        "            P = matrix(np.dot(np.dot(G, np.linalg.inv(HtH)), G.T), tc='d')\n",
        "            q = matrix(e, tc='d')\n",
        "            G_qp = matrix(np.vstack([-np.identity(e.shape[0]), np.identity(e.shape[0])]), tc='d')\n",
        "            h_qp = matrix(np.vstack([c * np.ones((e.shape[0], 1)), np.zeros((e.shape[0], 1))]), tc='d')\n",
        "\n",
        "            try:\n",
        "                sol = solvers.qp(P, q, G_qp, h_qp)\n",
        "                alpha = np.array(sol['x'])\n",
        "                return alpha\n",
        "            except Exception as e:\n",
        "                print(f\"QP problem failed: {e}\")\n",
        "                return None\n",
        "\n",
        "        # First hyperplane\n",
        "        alpha1 = solve_qp(H, G, e2, self.c1, self.reg_term)\n",
        "        if alpha1 is None:\n",
        "            print(\"Failed to solve QP for the first hyperplane.\")\n",
        "            return self\n",
        "\n",
        "        w1_b1 = -np.dot(np.linalg.inv(np.dot(H.T, H) + self.reg_term * np.identity(H.shape[1])), np.dot(G.T, alpha1))\n",
        "        self.w1 = w1_b1[:-1]\n",
        "        self.b1 = w1_b1[-1]\n",
        "\n",
        "        # Second hyperplane\n",
        "        alpha2 = solve_qp(G, H, e1, self.c2, self.reg_term)\n",
        "        if alpha2 is None:\n",
        "            print(\"Failed to solve QP for the second hyperplane.\")\n",
        "            return self\n",
        "\n",
        "        w2_b2 = np.dot(np.linalg.inv(np.dot(G.T, G) + self.reg_term * np.identity(G.shape[1])), np.dot(H.T, alpha2))\n",
        "        self.w2 = w2_b2[:-1]\n",
        "        self.b2 = w2_b2[-1]\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        dist_1 = np.abs(np.dot(X, self.w1) + self.b1)\n",
        "        dist_2 = np.abs(np.dot(X, self.w2) + self.b2)\n",
        "\n",
        "        return np.where(dist_1 < dist_2, 1, -1)\n",
        "\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        return accuracy_score(y, y_pred) # Call the accuracy_score function with y and y_pred\n"
      ],
      "metadata": {
        "id": "ump_6jUYel66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Breast Cancer Wisconsin dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Convert labels to +1 and -1\n",
        "y = np.where(y == 1, 1, -1)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA to reduce dimensionality\n",
        "pca = PCA(n_components=0.95)  # retain 95% of the variance\n",
        "X = pca.fit_transform(X)\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "# Perform feature selection\n",
        "selector = SelectKBest(f_classif, k=10)\n",
        "X = selector.fit_transform(X, y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "nPBFC_Lh2dY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'c1': [0.1, 1, 10, 100],\n",
        "    'c2': [0.1, 1, 10, 100],\n",
        "    'reg_term': [1e-5, 1e-4, 1e-3]\n",
        "}\n",
        "\n",
        "\n",
        "# Initialize TWSVM model\n",
        "twsvm = TWSVM()\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(twsvm, param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Train the model with the best parameters\n",
        "best_twsvm = grid_search.best_estimator_\n",
        "best_twsvm.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = best_twsvm.score(X_test, y_test)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNt0zIpO2iKY",
        "outputId": "8733c801-19c1-4fe8-ca72-e80f229cf2be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -2.0516e+01 -4.7473e+01  1e+03  2e+01  5e-16\n",
            " 1: -8.4349e+00 -4.3853e+01  2e+02  3e+00  5e-16\n",
            " 2: -5.4200e+00 -3.0106e+01  2e+01  4e-16  1e-15\n",
            " 3: -6.3873e+00 -1.0269e+01  4e+00  2e-16  5e-16\n",
            " 4: -7.6147e+00 -8.3158e+00  7e-01  2e-16  3e-16\n",
            " 5: -7.8724e+00 -8.0597e+00  2e-01  2e-16  3e-16\n",
            " 6: -7.9374e+00 -7.9848e+00  5e-02  2e-16  3e-16\n",
            " 7: -7.9567e+00 -7.9634e+00  7e-03  2e-16  3e-16\n",
            " 8: -7.9598e+00 -7.9600e+00  2e-04  2e-16  4e-16\n",
            " 9: -7.9599e+00 -7.9599e+00  4e-06  2e-16  3e-16\n",
            "Optimal solution found.\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -2.0453e+01 -4.5249e+01  9e+02  2e+01  3e-16\n",
            " 1: -1.3899e+01 -4.1207e+01  6e+01  7e-01  4e-16\n",
            " 2: -1.2945e+01 -2.0215e+01  7e+00  2e-16  6e-16\n",
            " 3: -1.3906e+01 -1.5564e+01  2e+00  2e-16  3e-16\n",
            " 4: -1.4347e+01 -1.4780e+01  4e-01  2e-16  2e-16\n",
            " 5: -1.4456e+01 -1.4626e+01  2e-01  2e-16  2e-16\n",
            " 6: -1.4505e+01 -1.4558e+01  5e-02  2e-16  2e-16\n",
            " 7: -1.4526e+01 -1.4532e+01  7e-03  2e-16  2e-16\n",
            " 8: -1.4529e+01 -1.4529e+01  1e-04  2e-16  2e-16\n",
            " 9: -1.4529e+01 -1.4529e+01  1e-06  2e-16  2e-16\n",
            "Optimal solution found.\n",
            "Best parameters: {'c1': 0.1, 'c2': 0.1, 'reg_term': 1e-05}\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -2.0516e+01 -4.7473e+01  1e+03  2e+01  5e-16\n",
            " 1: -8.4349e+00 -4.3853e+01  2e+02  3e+00  5e-16\n",
            " 2: -5.4200e+00 -3.0106e+01  2e+01  4e-16  1e-15\n",
            " 3: -6.3873e+00 -1.0269e+01  4e+00  2e-16  5e-16\n",
            " 4: -7.6147e+00 -8.3158e+00  7e-01  2e-16  3e-16\n",
            " 5: -7.8724e+00 -8.0597e+00  2e-01  2e-16  3e-16\n",
            " 6: -7.9374e+00 -7.9848e+00  5e-02  2e-16  3e-16\n",
            " 7: -7.9567e+00 -7.9634e+00  7e-03  2e-16  3e-16\n",
            " 8: -7.9598e+00 -7.9600e+00  2e-04  2e-16  4e-16\n",
            " 9: -7.9599e+00 -7.9599e+00  4e-06  2e-16  3e-16\n",
            "Optimal solution found.\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -2.0453e+01 -4.5249e+01  9e+02  2e+01  3e-16\n",
            " 1: -1.3899e+01 -4.1207e+01  6e+01  7e-01  4e-16\n",
            " 2: -1.2945e+01 -2.0215e+01  7e+00  2e-16  6e-16\n",
            " 3: -1.3906e+01 -1.5564e+01  2e+00  2e-16  3e-16\n",
            " 4: -1.4347e+01 -1.4780e+01  4e-01  2e-16  2e-16\n",
            " 5: -1.4456e+01 -1.4626e+01  2e-01  2e-16  2e-16\n",
            " 6: -1.4505e+01 -1.4558e+01  5e-02  2e-16  2e-16\n",
            " 7: -1.4526e+01 -1.4532e+01  7e-03  2e-16  2e-16\n",
            " 8: -1.4529e+01 -1.4529e+01  1e-04  2e-16  2e-16\n",
            " 9: -1.4529e+01 -1.4529e+01  1e-06  2e-16  2e-16\n",
            "Optimal solution found.\n",
            "Accuracy: 97.67%\n"
          ]
        }
      ]
    }
  ]
}